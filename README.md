This was started as a project for my machine learning course, however I may continue it afterwards.

Libraries are used for input preprocessing, text embedding/vectorization, etc. The self-attention algorithm, the heart of the transformer, will be coded entirely by me.
